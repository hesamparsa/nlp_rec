{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70fe1ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import types\n",
    "\n",
    "from transformers4rec import torch as tr\n",
    "from transformers4rec.torch.ranking_metric import NDCGAt, AvgPrecisionAt, RecallAt\n",
    "from transformers4rec.torch.utils.examples_utils import wipe_memory\n",
    "from transformers4rec.config.trainer import T4RecTrainingArguments\n",
    "from transformers4rec.torch import Trainer\n",
    "from merlin_standard_lib import Schema\n",
    "\n",
    "from mlflow_databricks import MLFlowWrapper\n",
    "from transformers.integrations import MLflowCallback, TrainerCallback\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b21937f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_dataloader(self, test_path=None):\n",
    "        from transformers4rec.torch.utils.data_utils import T4RecDataLoader\n",
    "        \"\"\"\n",
    "        Set the test dataloader to use by Trainer.\n",
    "        It supports user defined data-loader set as an attribute in the constructor.\n",
    "        When the attribute is None, The data-loader is defined using eval_dataset\n",
    "        and the `data_loader_engine` specified in Training Arguments.\n",
    "        \n",
    "        JN: needed to hotfix this into the trainer, the original one is missing this method and it breaks the predict function. \n",
    "        \"\"\"\n",
    "\n",
    "        assert self.schema is not None, \"schema is required to generate Test Dataloader\"\n",
    "        return T4RecDataLoader.parse(self.args.data_loader_engine).from_schema(\n",
    "            self.schema,\n",
    "            test_path,\n",
    "            self.args.per_device_eval_batch_size,\n",
    "            max_sequence_length=self.args.max_sequence_length,\n",
    "            drop_last=False,\n",
    "            shuffle=False,\n",
    "            shuffle_buffer_size=self.args.shuffle_buffer_size,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c63468b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCHEMA_PATH = \"sample_schema2.pb\"\n",
    "OVERWRITE_SCHEMA = False\n",
    "mapping_path=\"maps\"\n",
    "category_cols = [\"user_session\",\"category_code\",\"brand\",\"user_id\",\"product_id\"]\n",
    "group_cols = [\"category_code\",\"brand\",\"product_id\",\"rel_time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c7389fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = Schema().from_proto_text(SCHEMA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af4af4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tr.TabularSequenceFeatures.from_schema(\n",
    "        schema,\n",
    "        max_sequence_length=20,\n",
    "        continuous_projection=64,\n",
    "        d_output=128,\n",
    "        masking=\"mlm\",\n",
    "        embedding_dims={\"category_code\":32,\"product_id\":64, \"brand\":32}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb5e09f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define XLNetConfig class and set default parameters for HF XLNet config  \n",
    "transformer_config = tr.XLNetConfig.build(\n",
    "    d_model=64, n_head=4, n_layer=2, total_seq_length=20\n",
    ")\n",
    "# Define the model block including: inputs, masking, projection and transformer block.\n",
    "body = tr.SequentialBlock(\n",
    "    inputs, tr.MLPBlock([64]), tr.TransformerBlock(transformer_config, masking=inputs.masking)\n",
    ")\n",
    "\n",
    "# Defines the evaluation top-N metrics and the cut-offs\n",
    "metrics = [NDCGAt(top_ks=[20, 40], labels_onehot=True),  \n",
    "           RecallAt(top_ks=[20, 40], labels_onehot=True)]\n",
    "\n",
    "# Define a head related to next item prediction task \n",
    "head = tr.Head(\n",
    "    body,\n",
    "    tr.NextItemPredictionTask(weight_tying=True, hf_format=True, \n",
    "                              metrics=metrics),\n",
    "    inputs=inputs,\n",
    ")\n",
    "\n",
    "# Get the end-to-end Model class \n",
    "model = tr.Model(head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "067b81d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyperparameters for training \n",
    "train_args = T4RecTrainingArguments(data_loader_engine='pyarrow', \n",
    "                                    dataloader_drop_last = True,\n",
    "                                    report_to = [\"mlflow\"], \n",
    "                                    gradient_accumulation_steps = 1,\n",
    "                                    per_device_train_batch_size = 256, \n",
    "                                    per_device_eval_batch_size = 32,\n",
    "                                    output_dir = \"./tmp\", \n",
    "                                    learning_rate=0.0005,\n",
    "                                    lr_scheduler_type='cosine', \n",
    "                                    learning_rate_num_cosine_cycles_by_epoch=1.5,\n",
    "                                    num_train_epochs=2,\n",
    "                                    max_sequence_length=40, \n",
    "                                    no_cuda=False,\n",
    "                                    compute_metrics_each_n_steps=1000,\n",
    "                                    # validate_every=100, code docstr makes it seem like this should exist but it doesnt....\n",
    "                                    save_steps=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8f2e0cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting into vault authentication --->\n",
      "VAULT_ROLE_ENV :=dev\n",
      "VAULT_ROLE :=pdo-digpersistent\n",
      "Vault URL :https://vault.vaultenterprisedev.aws.gartner.com\n",
      "[INFO|mlflow_wrapper.py:93] 2022-01-13 15:51:40,598 >> Starting up mlflow\n"
     ]
    }
   ],
   "source": [
    "mlf = MLFlowWrapper(\"scratch\",server=\"databricks\",run_name=\"transformer4rec\")\n",
    "mlf.pre_trainer(model_type=\"huggingface\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7fb1a9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    schema=schema,\n",
    "    args=train_args,\n",
    "    train_dataset_or_path=\"sample_train.parquet\",\n",
    "    eval_dataset_or_path=\"sample_val.parquet\",\n",
    "    compute_metrics=True,\n",
    "    #callbacks=[MLflowCallback],\n",
    "    #incremental_logging=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09a5415c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer works mainly like huggingface, but this method is missing for the prediction step\n",
    "trainer.get_test_dataloader =  types.MethodType( get_test_dataloader, trainer )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc8dbb47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 500224\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 256\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 256\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3908\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3908' max='3908' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3908/3908 07:41, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>10.109800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>9.535300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>9.286800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>9.208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>9.744000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>9.359000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>9.182700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./tmp/checkpoint-2000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3908, training_loss=9.439782539922115, metrics={'train_runtime': 461.9858, 'train_samples_per_second': 0.004, 'train_steps_per_second': 8.459, 'total_flos': 0.0, 'train_loss': 9.439782539922115})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e79ea61b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/t4rec/lib/python3.8/site-packages/transformers4rec/torch/ranking_metric.py:129: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /opt/conda/conda-bld/pytorch_1603729009598/work/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
      "  rel_indices = (num_relevant != 0).nonzero()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31277' max='15638' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15638/15638 15:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eval_metrics = trainer.evaluate(metric_key_prefix='eval')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "971be809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval/next-item/ndcg_at_20': 0.02318193018436432,\n",
       " 'eval/next-item/ndcg_at_40': 0.02807333879172802,\n",
       " 'eval/next-item/recall_at_20': 0.05078125,\n",
       " 'eval/next-item/recall_at_40': 0.07421875,\n",
       " 'eval/loss': 9.721333503723145,\n",
       " 'eval_runtime': 287.2914,\n",
       " 'eval_samples_per_second': 1741.841,\n",
       " 'eval_steps_per_second': 54.433}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fd9c1258",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_files = [os.path.join(mapping_path,x) for x in os.listdir(mapping_path)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "383026ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO|mlflow_wrapper.py:154] 2021-12-20 21:04:31,692 >> MLFLOW: begining to log model\n",
      "[INFO|mlflow_wrapper.py:171] 2021-12-20 21:04:42,685 >> MLFLOW: begining to log metrics\n",
      "[INFO|mlflow_wrapper.py:180] 2021-12-20 21:04:43,982 >> MLFLOW: begining to log artifacts\n",
      "[INFO|mlflow_wrapper.py:183] 2021-12-20 21:04:43,983 >> MLFLOW: Logging file sample_schema2.pb\n",
      "[INFO|mlflow_wrapper.py:183] 2021-12-20 21:04:44,350 >> MLFLOW: Logging file maps/user_session.csv\n",
      "[INFO|mlflow_wrapper.py:183] 2021-12-20 21:05:16,126 >> MLFLOW: Logging file maps/category_code.csv\n",
      "[INFO|mlflow_wrapper.py:183] 2021-12-20 21:05:47,108 >> MLFLOW: Logging file maps/brand.csv\n",
      "[INFO|mlflow_wrapper.py:183] 2021-12-20 21:06:15,178 >> MLFLOW: Logging file maps/user_id.csv\n",
      "[INFO|mlflow_wrapper.py:183] 2021-12-20 21:06:47,452 >> MLFLOW: Logging file maps/product_id.csv\n",
      "[INFO|mlflow_wrapper.py:193] 2021-12-20 21:07:18,230 >> Setting experiment permissions for: /Users/7fa96ba7-8869-429e-b213-e2bd1c6082e3/scratch\n"
     ]
    }
   ],
   "source": [
    "mlf.post_trainer(model=trainer.model,model_type='huggingface',metrics=eval_metrics,\n",
    "                artifacts=[SCHEMA_PATH]+mapping_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "15c9fc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0420db7d",
   "metadata": {},
   "source": [
    "# Predictions\n",
    "Predict outputs  the top n items and scores. The n is set in the training args. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5aa276e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = trainer.predict(\"sample_train.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bda8f8b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 89,  55,  72, ...,  19, 105, 100],\n",
       "       [ 89,  55,  72, ...,  19, 105, 100],\n",
       "       [ 89,  55, 114, ...,  19, 105, 100],\n",
       "       ...,\n",
       "       [ 89,  55,  72, ...,  19, 105, 100],\n",
       "       [ 89,  55,  72, ...,  19, 105, 100],\n",
       "       [ 89,  55,  72, ...,  19, 105, 100]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predicted items\n",
    "pred.predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2404fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 89,  55,  72, 114,  43,  51,  69,  19, 105, 100])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.predictions[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "71b5796e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 55, 114,  89, 100, 105, 532,  75,  51,  43,  72])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.predictions[0][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "31a37ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pd.read_parquet('sample_val.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f0b28962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_session</th>\n",
       "      <th>event_type</th>\n",
       "      <th>product_id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>category_code</th>\n",
       "      <th>brand</th>\n",
       "      <th>price</th>\n",
       "      <th>user_id</th>\n",
       "      <th>event_time_ts</th>\n",
       "      <th>prod_first_event_time_ts</th>\n",
       "      <th>rel_time</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>[35597, 17799]</td>\n",
       "      <td>[2053013553559896355, 2053013553559896355]</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>[678, 537]</td>\n",
       "      <td>[69.89, 72.59]</td>\n",
       "      <td>[513605798, 513605798]</td>\n",
       "      <td>[1570452448, 1570452484]</td>\n",
       "      <td>[1569914121, 1569902730]</td>\n",
       "      <td>[538327.0, 549754.0]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>[16211, 1245]</td>\n",
       "      <td>[2172371436436455782, 2172371436436455782]</td>\n",
       "      <td>[35, 35]</td>\n",
       "      <td>[11, 11]</td>\n",
       "      <td>[477.40999999999997, 238.48000000000002]</td>\n",
       "      <td>[491844619, 491844619]</td>\n",
       "      <td>[1570337853, 1570337872]</td>\n",
       "      <td>[1569902010, 1569896513]</td>\n",
       "      <td>[435843.0, 441359.0]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>[734, 23602]</td>\n",
       "      <td>[2053013554415534427, 2053013554415534427]</td>\n",
       "      <td>[11, 11]</td>\n",
       "      <td>[41, 41]</td>\n",
       "      <td>[486.24, 447.37]</td>\n",
       "      <td>[513068111, 513068111]</td>\n",
       "      <td>[1570140667, 1570140681]</td>\n",
       "      <td>[1569896288, 1569905833]</td>\n",
       "      <td>[244379.0, 234848.0]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>[14844, 11442]</td>\n",
       "      <td>[2053013553945772349, 2053013553945772349]</td>\n",
       "      <td>[41, 41]</td>\n",
       "      <td>[144, 144]</td>\n",
       "      <td>[49.54, 25.74]</td>\n",
       "      <td>[522539566, 522539566]</td>\n",
       "      <td>[1570019649, 1570019663]</td>\n",
       "      <td>[1569901408, 1569900026]</td>\n",
       "      <td>[118241.0, 119637.0]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>[43759, 89957]</td>\n",
       "      <td>[2053013563651392361, 2053013563651392361]</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>[3, 33]</td>\n",
       "      <td>[359.68, 287.52]</td>\n",
       "      <td>[512805595, 512805595]</td>\n",
       "      <td>[1570295859, 1570295926]</td>\n",
       "      <td>[1569921644, 1570090595]</td>\n",
       "      <td>[374215.0, 205331.0]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_session event_type      product_id  \\\n",
       "0             1     [1, 1]  [35597, 17799]   \n",
       "1             6     [1, 1]   [16211, 1245]   \n",
       "2            17     [1, 1]    [734, 23602]   \n",
       "3            22     [1, 1]  [14844, 11442]   \n",
       "4            26     [1, 1]  [43759, 89957]   \n",
       "\n",
       "                                  category_id category_code       brand  \\\n",
       "0  [2053013553559896355, 2053013553559896355]        [2, 2]  [678, 537]   \n",
       "1  [2172371436436455782, 2172371436436455782]      [35, 35]    [11, 11]   \n",
       "2  [2053013554415534427, 2053013554415534427]      [11, 11]    [41, 41]   \n",
       "3  [2053013553945772349, 2053013553945772349]      [41, 41]  [144, 144]   \n",
       "4  [2053013563651392361, 2053013563651392361]        [2, 2]     [3, 33]   \n",
       "\n",
       "                                      price                 user_id  \\\n",
       "0                            [69.89, 72.59]  [513605798, 513605798]   \n",
       "1  [477.40999999999997, 238.48000000000002]  [491844619, 491844619]   \n",
       "2                          [486.24, 447.37]  [513068111, 513068111]   \n",
       "3                            [49.54, 25.74]  [522539566, 522539566]   \n",
       "4                          [359.68, 287.52]  [512805595, 512805595]   \n",
       "\n",
       "              event_time_ts  prod_first_event_time_ts              rel_time  \\\n",
       "0  [1570452448, 1570452484]  [1569914121, 1569902730]  [538327.0, 549754.0]   \n",
       "1  [1570337853, 1570337872]  [1569902010, 1569896513]  [435843.0, 441359.0]   \n",
       "2  [1570140667, 1570140681]  [1569896288, 1569905833]  [244379.0, 234848.0]   \n",
       "3  [1570019649, 1570019663]  [1569901408, 1569900026]  [118241.0, 119637.0]   \n",
       "4  [1570295859, 1570295926]  [1569921644, 1570090595]  [374215.0, 205331.0]   \n",
       "\n",
       "   len  \n",
       "0    2  \n",
       "1    2  \n",
       "2    2  \n",
       "3    2  \n",
       "4    2  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a4e97df6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-6.3711824, -6.508836 , -6.549979 , ..., -6.9555006, -7.0562887,\n",
       "        -7.0823975],\n",
       "       [-6.3711824, -6.508836 , -6.549979 , ..., -6.9555006, -7.0562887,\n",
       "        -7.0823975],\n",
       "       [-6.3711824, -6.508836 , -6.549979 , ..., -6.9555006, -7.0562887,\n",
       "        -7.0823975],\n",
       "       ...,\n",
       "       [-6.371183 , -6.5088367, -6.54998  , ..., -6.9555016, -7.0562897,\n",
       "        -7.082398 ],\n",
       "       [-6.371183 , -6.5088367, -6.54998  , ..., -6.9555016, -7.0562897,\n",
       "        -7.082398 ],\n",
       "       [-6.371183 , -6.5088367, -6.54998  , ..., -6.9555016, -7.0562897,\n",
       "        -7.082398 ]], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predicted scores\n",
    "pred.predictions[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3909d6e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95754, 10)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.predictions[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9409e3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_parquet(\"sample_test.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ef712753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95754, 6)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c64b97ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>category_code</th>\n",
       "      <th>brand</th>\n",
       "      <th>product_id</th>\n",
       "      <th>rel_time</th>\n",
       "      <th>item_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>861784</td>\n",
       "      <td>[17]</td>\n",
       "      <td>[87]</td>\n",
       "      <td>[1220]</td>\n",
       "      <td>[277043.0]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>861785</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[9]</td>\n",
       "      <td>[17365]</td>\n",
       "      <td>[175049.0]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>861786</td>\n",
       "      <td>[66]</td>\n",
       "      <td>[574]</td>\n",
       "      <td>[5919]</td>\n",
       "      <td>[368361.0]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>861787</td>\n",
       "      <td>[4]</td>\n",
       "      <td>[16]</td>\n",
       "      <td>[4258]</td>\n",
       "      <td>[367198.0]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>861788</td>\n",
       "      <td>[4]</td>\n",
       "      <td>[149]</td>\n",
       "      <td>[2585]</td>\n",
       "      <td>[396595.0]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id category_code  brand product_id    rel_time  item_count\n",
       "0   861784          [17]   [87]     [1220]  [277043.0]           1\n",
       "1   861785           [1]    [9]    [17365]  [175049.0]           1\n",
       "2   861786          [66]  [574]     [5919]  [368361.0]           1\n",
       "3   861787           [4]   [16]     [4258]  [367198.0]           1\n",
       "4   861788           [4]  [149]     [2585]  [396595.0]           1"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca14e9fc",
   "metadata": {},
   "source": [
    "# Scratch and stuff in previous notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5522e490",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a539254",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3609c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ac6412",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "355ca775",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = \".\"#os.environ.get(\"OUTPUT_DIR\", \"/workspace/data/sessions_by_day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac2c416d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/workspace/data/sessions_by_day/1/train.parquet']\n",
      "********************\n",
      "Launch training for day 1 are:\n",
      "********************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 768\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 256\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 256\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 15\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:00, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "Eval results for day 2 are:\t\n",
      "\n",
      "********************\n",
      "\n",
      " eval/loss = 10.3350191116333\n",
      " eval/next-item/ndcg_at_20 = 0.011259923689067364\n",
      " eval/next-item/ndcg_at_40 = 0.011259923689067364\n",
      " eval/next-item/recall_at_20 = 0.0416666679084301\n",
      " eval/next-item/recall_at_40 = 0.0416666679084301\n",
      " eval_runtime = 0.1209\n",
      " eval_samples_per_second = 794.045\n",
      " eval_steps_per_second = 24.814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 768\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 256\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 256\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/workspace/data/sessions_by_day/2/train.parquet']\n",
      "********************\n",
      "Launch training for day 2 are:\n",
      "********************\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:00, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n",
      "********************\n",
      "Eval results for day 3 are:\t\n",
      "\n",
      "********************\n",
      "\n",
      " eval/loss = 9.907649040222168\n",
      " eval/next-item/ndcg_at_20 = 0.07261061668395996\n",
      " eval/next-item/ndcg_at_40 = 0.09025609493255615\n",
      " eval/next-item/recall_at_20 = 0.21875\n",
      " eval/next-item/recall_at_40 = 0.3020833432674408\n",
      " eval_runtime = 0.1604\n",
      " eval_samples_per_second = 598.353\n",
      " eval_steps_per_second = 18.699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 768\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 256\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 256\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/workspace/data/sessions_by_day/3/train.parquet']\n",
      "********************\n",
      "Launch training for day 3 are:\n",
      "********************\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:00, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n",
      "********************\n",
      "Eval results for day 4 are:\t\n",
      "\n",
      "********************\n",
      "\n",
      " eval/loss = 9.442419052124023\n",
      " eval/next-item/ndcg_at_20 = 0.10495926439762115\n",
      " eval/next-item/ndcg_at_40 = 0.13046541810035706\n",
      " eval/next-item/recall_at_20 = 0.3020833432674408\n",
      " eval/next-item/recall_at_40 = 0.4270833432674408\n",
      " eval_runtime = 0.1071\n",
      " eval_samples_per_second = 896.554\n",
      " eval_steps_per_second = 28.017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 768\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 256\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 256\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/workspace/data/sessions_by_day/4/train.parquet']\n",
      "********************\n",
      "Launch training for day 4 are:\n",
      "********************\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:00, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n",
      "********************\n",
      "Eval results for day 5 are:\t\n",
      "\n",
      "********************\n",
      "\n",
      " eval/loss = 8.860241889953613\n",
      " eval/next-item/ndcg_at_20 = 0.11112610995769501\n",
      " eval/next-item/ndcg_at_40 = 0.1652408242225647\n",
      " eval/next-item/recall_at_20 = 0.3333333432674408\n",
      " eval/next-item/recall_at_40 = 0.59375\n",
      " eval_runtime = 0.1023\n",
      " eval_samples_per_second = 938.1\n",
      " eval_steps_per_second = 29.316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 768\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 256\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 256\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/workspace/data/sessions_by_day/5/train.parquet']\n",
      "********************\n",
      "Launch training for day 5 are:\n",
      "********************\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:00, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n",
      "********************\n",
      "Eval results for day 6 are:\t\n",
      "\n",
      "********************\n",
      "\n",
      " eval/loss = 8.344633102416992\n",
      " eval/next-item/ndcg_at_20 = 0.10326863825321198\n",
      " eval/next-item/ndcg_at_40 = 0.17447516322135925\n",
      " eval/next-item/recall_at_20 = 0.2395833432674408\n",
      " eval/next-item/recall_at_40 = 0.59375\n",
      " eval_runtime = 0.1037\n",
      " eval_samples_per_second = 925.533\n",
      " eval_steps_per_second = 28.923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 768\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 256\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 256\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/workspace/data/sessions_by_day/6/train.parquet']\n",
      "********************\n",
      "Launch training for day 6 are:\n",
      "********************\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:00, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n",
      "********************\n",
      "Eval results for day 7 are:\t\n",
      "\n",
      "********************\n",
      "\n",
      " eval/loss = 7.80819845199585\n",
      " eval/next-item/ndcg_at_20 = 0.15623269975185394\n",
      " eval/next-item/ndcg_at_40 = 0.1892910897731781\n",
      " eval/next-item/recall_at_20 = 0.3854166865348816\n",
      " eval/next-item/recall_at_40 = 0.5520833730697632\n",
      " eval_runtime = 0.101\n",
      " eval_samples_per_second = 950.741\n",
      " eval_steps_per_second = 29.711\n"
     ]
    }
   ],
   "source": [
    "start_time_window_index = 1\n",
    "final_time_window_index = 7\n",
    "#Iterating over days of one week\n",
    "for time_index in range(start_time_window_index, final_time_window_index):\n",
    "    # Set data \n",
    "    time_index_train = time_index\n",
    "    time_index_eval = time_index + 1\n",
    "    train_paths = glob.glob(os.path.join(OUTPUT_DIR, f\"{time_index_train}/train.parquet\"))\n",
    "    eval_paths = glob.glob(os.path.join(OUTPUT_DIR, f\"{time_index_eval}/valid.parquet\"))\n",
    "    print(train_paths)\n",
    "    \n",
    "    # Train on day related to time_index \n",
    "    print('*'*20)\n",
    "    print(\"Launch training for day %s are:\" %time_index)\n",
    "    print('*'*20 + '\\n')\n",
    "    trainer.train_dataset_or_path = train_paths\n",
    "    trainer.reset_lr_scheduler()\n",
    "    trainer.train()\n",
    "    trainer.state.global_step +=1\n",
    "    print('finished')\n",
    "    \n",
    "    # Evaluate on the following day\n",
    "    trainer.eval_dataset_or_path = eval_paths\n",
    "    train_metrics = trainer.evaluate(metric_key_prefix='eval')\n",
    "    print('*'*20)\n",
    "    print(\"Eval results for day %s are:\\t\" %time_index_eval)\n",
    "    print('\\n' + '*'*20 + '\\n')\n",
    "    for key in sorted(train_metrics.keys()):\n",
    "        print(\" %s = %s\" % (key, str(train_metrics[key]))) \n",
    "    wipe_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90290cc",
   "metadata": {},
   "source": [
    "### Saves the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9bc365b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./tmp/checkpoint-16\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n"
     ]
    }
   ],
   "source": [
    "trainer._save_model_and_checkpoint(save_model_class=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea546269",
   "metadata": {},
   "source": [
    "### Reloads the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ced61b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.load_model_trainer_states_from_checkpoint('./tmp/checkpoint-%s'%trainer.state.global_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3ba0da",
   "metadata": {},
   "source": [
    "### Re-compute eval metrics of validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "303366b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data_paths = glob.glob(os.path.join(OUTPUT_DIR, f\"{time_index_eval}/valid.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "64d862c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  eval/loss = 7.80819845199585\n",
      "  eval/next-item/ndcg_at_20 = 0.15623269975185394\n",
      "  eval/next-item/ndcg_at_40 = 0.1892910897731781\n",
      "  eval/next-item/recall_at_20 = 0.3854166865348816\n",
      "  eval/next-item/recall_at_40 = 0.5520833730697632\n",
      "  eval_runtime = 0.1228\n",
      "  eval_samples_per_second = 781.569\n",
      "  eval_steps_per_second = 24.424\n"
     ]
    }
   ],
   "source": [
    "# set new data from day 7\n",
    "eval_metrics = trainer.evaluate(eval_dataset=eval_data_paths, metric_key_prefix='eval')\n",
    "for key in sorted(eval_metrics.keys()):\n",
    "    print(\"  %s = %s\" % (key, str(eval_metrics[key])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4038f33b",
   "metadata": {},
   "source": [
    "That's it!  \n",
    "You have just trained your session-based recommendation model using Transformers4Rec."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c521ff",
   "metadata": {},
   "source": [
    "Tip: We can easily log and visualize model training and evaluation on [Weights & Biases (W&B)](https://wandb.ai/home), [Tensorboard](https://www.tensorflow.org/tensorboard) and [NVIDIA DLLogger](https://github.com/NVIDIA/dllogger). By default, the HuggingFace transformers `Trainer` (which we extend) uses Weights & Biases (W&B) to log training and evaluation metrics, which provides nice results visualization and comparison between different runs."
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "interpreter": {
   "hash": "7b543a88d374ac88bf8df97911b380f671b13649694a5b49eb21e60fd27eb479"
  },
  "kernelspec": {
   "display_name": "conda_t4rec",
   "language": "python",
   "name": "conda_t4rec"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
